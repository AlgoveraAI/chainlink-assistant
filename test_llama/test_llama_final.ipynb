{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python-dotenv could not parse statement starting at line 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"/home/marshath/play/chainlink/algovate/.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "# logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "# logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import Document\n",
    "from llama_index.node_parser import SimpleNodeParser\n",
    "from llama_index import GPTVectorStoreIndex, ResponseSynthesizer\n",
    "from llama_index.data_structs.node import Node, DocumentRelationship\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from llama_index.retrievers import VectorIndexRetriever\n",
    "from llama_index.query_engine import RetrieverQueryEngine\n",
    "from llama_index.indices.postprocessor import SimilarityPostprocessor\n",
    "from llama_index import LLMPredictor, GPTVectorStoreIndex, PromptHelper, ServiceContext\n",
    "from llama_index import GPTListIndex\n",
    "from llama_index.indices.list.retrievers import ListIndexLLMRetriever\n",
    "from llama_index.indices.postprocessor import (\n",
    "    LLMRerank\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "with open('/home/marshath/play/chainlink/algovate/algovate/data/documents.pkl', 'rb') as f:\n",
    "    cl_techdoc = pickle.load(f)\n",
    "\n",
    "# convert to llama documents\n",
    "llama_cl_techdoc = []\n",
    "for doc in cl_techdoc:\n",
    "    llama_cl_techdoc.append(Document(text=doc.page_content, extra_info=doc.metadata))\n",
    "\n",
    "with open('/home/marshath/play/chainlink/algovate/algovate/data/combined_documents.pkl', 'rb') as f:\n",
    "    cl_combineddoc = pickle.load(f)\n",
    "\n",
    "# convert to llama documents\n",
    "llama_cl_combineddoc = []\n",
    "for doc in cl_combineddoc:\n",
    "    llama_cl_combineddoc.append(Document(text=doc.page_content, extra_info=doc.metadata))\n",
    "\n",
    "# load the ground truths\n",
    "with open(\"/home/marshath/play/chainlink/algovate/algovate/data/ground_truths.pkl\", \"rb\") as f:\n",
    "    ground_truths = pickle.load(f)\n",
    "\n",
    "df = pd.DataFrame(ground_truths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert it to nodes\n",
    "parser = SimpleNodeParser()\n",
    "cl_techdoc_nodes = parser.get_nodes_from_documents(llama_cl_techdoc)\n",
    "cl_combineddoc_nodes = parser.get_nodes_from_documents(llama_cl_combineddoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_docs(df, query_engine):\n",
    "    # Add retrieved_docs column if it doesn't exist\n",
    "    df['retrieved_docs'] = df.get('retrieved_docs', '')\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        retrieved_docs = query_engine.retrieve(row['question'])\n",
    "\n",
    "        docs = \"\"\n",
    "        for d in retrieved_docs:\n",
    "            if docs == \"\":\n",
    "                docs = d.node.text\n",
    "            else:\n",
    "                docs = docs + \"\\n\\n:::NEXT DOC:::\\n\\n\" + d.node.text\n",
    "\n",
    "        # Store retrieved docs in the DataFrame\n",
    "        df.at[index, 'retrieved_docs'] = docs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_predictor = LLMPredictor(llm=ChatOpenAI(temperature=0,))\n",
    "\n",
    "max_input_size = 4096\n",
    "num_output = 256\n",
    "max_chunk_overlap = 20\n",
    "\n",
    "prompt_helper = PromptHelper(max_input_size, num_output, max_chunk_overlap)\n",
    "\n",
    "service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor, prompt_helper=prompt_helper)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### techdoc only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_base_techdoc = GPTVectorStoreIndex.from_documents(\n",
    "    llama_cl_techdoc, \n",
    "    service_context=service_context\n",
    ")\n",
    "\n",
    "query_engine_base_techdoc = index_base_techdoc.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()\n",
    "for i, gt in df1.iterrows():\n",
    "    try:\n",
    "        df1.loc[i, \"result\"] = query_engine_base_techdoc.query(gt.question)\n",
    "    except Exception as e:\n",
    "        logger.error(e)\n",
    "        df1.loc[i, \"result\"] = \"ERROR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve_docs(df1, query_engine_base_techdoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(\"/home/marshath/play/chainlink/algovate/test_llama/techdoc_base.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### combineddocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_base_combineddoc = GPTVectorStoreIndex.from_documents(\n",
    "    llama_cl_combineddoc, \n",
    "    service_context=service_context\n",
    ")\n",
    "\n",
    "query_engine_base_combineddoc = index_base_combineddoc.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "for i, gt in df2.iterrows():\n",
    "    try:\n",
    "        df2.loc[i, \"result\"] = query_engine_base_combineddoc.query(gt.question)\n",
    "    except Exception as e:\n",
    "        logger.error(e)\n",
    "        df2.loc[i, \"result\"] = \"ERROR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve_docs(df2, query_engine_base_combineddoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(\"/home/marshath/play/chainlink/algovate/test_llama/combineddoc_base.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLMReranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on https://medium.com/llamaindex-blog/using-llms-for-retrieval-and-reranking-23cf2d3a14b6\n",
    "llm_predictor = LLMPredictor(llm=ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\"))\n",
    "service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor, chunk_size_limit=512)\n",
    "reranker = LLMRerank(choice_batch_size=5, top_n=3, service_context=service_context)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### techdoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_llmreranker_techdoc = GPTVectorStoreIndex.from_documents(llama_cl_techdoc, service_context=service_context)\n",
    "\n",
    "query_engine_llmreranker_techdoc = index_llmreranker_techdoc.as_query_engine(\n",
    "    similarity_top_k=10,\n",
    "    node_postprocessors=[reranker],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chainlink",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
