{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "import tiktoken\n",
    "from pydantic import BaseModel\n",
    "from typing import Any, Dict, List\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema import BaseRetriever\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.callbacks.manager import AsyncCallbackManager\n",
    "from langchain.text_splitter import TokenTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "# Formatter\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "# stream handler\n",
    "stream_handler = logging.StreamHandler()\n",
    "stream_handler.setLevel(logging.INFO)\n",
    "stream_handler.setFormatter(formatter)\n",
    "logger.addHandler(stream_handler)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data docs in retriever "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/marshath/play/chainlink/chainlink-assistant/data/datadocs_2023-08-16.pkl\", \"rb\") as f:\n",
    "    data_docs = pickle.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1200, chunk_overlap=100)\n",
    "split_docs = splitter.split_documents(data_docs)\n",
    "vectorstrore = FAISS.from_documents(split_docs, OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = vectorstrore.as_retriever(search_kwargs={\"k\":4})\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.)\n",
    "chain = RetrievalQAWithSourcesChain.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The contract address for ATOM / USD on the Moonbeam network is \"0x4f152d143c97b5e8d2293bc5b2380600f274a5dd\".\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ques = \"what is the contract address for ATOM / USD on moonbeam network?\"\n",
    "r_docs = ret.get_relevant_documents(ques)\n",
    "answer = chain(ques)\n",
    "Markdown(answer[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The following is the details for the pair AAVE / USD which operates on the Metis Mainnet. This asset is named \"Aave\". and falls under the \"Crypto\" asset class. It has a tier status of \"Verified\". The deviation threshold for this asset is set at 0.5%. 15 / 15 oracles carries and support this asset. You can find its contract at the address \"0x54389e89a5ec1d4312d5b5c48055d6e56a177bf9"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(r_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three point router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomeSplitter:\n",
    "    def __init__(self, chunk_threshold=6000, chunk_size=6000, chunk_overlap=50):\n",
    "        self.chunk_threshold = chunk_threshold\n",
    "        self.chunk_size = chunk_size\n",
    "        self.chunk_overlap = chunk_overlap\n",
    "        self.enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "        self.splitter = TokenTextSplitter(\n",
    "            chunk_size=chunk_size, \n",
    "            chunk_overlap=chunk_overlap\n",
    "        )\n",
    "\n",
    "    def token_counter(self, document):\n",
    "        tokens = self.enc.encode(document.page_content)\n",
    "        return len(tokens)\n",
    "\n",
    "    def split(self, documents):\n",
    "        chunked_documents = []\n",
    "        for i, doc in enumerate(documents):\n",
    "            try:\n",
    "                if self.token_counter(doc) > self.chunk_threshold:\n",
    "                    chunks = self.splitter.split_documents([doc])\n",
    "                    chunks = [\n",
    "                        Document(\n",
    "                            page_content=chunk.page_content,\n",
    "                            metadata={\n",
    "                                \"source\": f\"{chunk.metadata['source']} chunk {i}\"\n",
    "                            },\n",
    "                        )\n",
    "                        for i, chunk in enumerate(chunks)\n",
    "                    ]\n",
    "                    chunked_documents.extend(chunks)\n",
    "                else:\n",
    "                    chunked_documents.append(doc)\n",
    "            except Exception as e:\n",
    "                chunked_documents.append(doc)\n",
    "                print(f\"Error on document {i}\")\n",
    "                print(e)\n",
    "                print(doc.metadata[\"source\"])\n",
    "\n",
    "        return chunked_documents\n",
    "\n",
    "\n",
    "class CustomRetriever(BaseRetriever, BaseModel):\n",
    "    full_docs: List[Document]\n",
    "    base_retriever_all: BaseRetriever = None\n",
    "    base_retriever_data: BaseRetriever = None\n",
    "    k_initial: int = 10\n",
    "    k_final: int = 4\n",
    "\n",
    "    logger: Any = None\n",
    "\n",
    "    class Config:\n",
    "        \"\"\"Configuration for this pydantic object.\"\"\"\n",
    "\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    @classmethod\n",
    "    def from_documents(\n",
    "        cls,\n",
    "        full_docs: List[Document],\n",
    "        vectorstore_all: FAISS,\n",
    "        vectorstore_data: FAISS,\n",
    "        search_kwargs: Dict[str, Any] = {},\n",
    "        k_initial: int = 10,\n",
    "        k_final: int = 4,\n",
    "        logger: Any = None,\n",
    "        **kwargs: Any,\n",
    "    ):\n",
    "        # splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=50)\n",
    "        # split_docs = splitter.split_documents(full_docs)\n",
    "        # vector_store = FAISS.from_documents(split_docs, embedding=OpenAIEmbeddings())\n",
    "\n",
    "        return cls(\n",
    "            full_docs=full_docs,\n",
    "            base_retriever_all=vectorstore_all.as_retriever(search_kwargs={\"k\": k_initial}),\n",
    "            base_retriever_data=vectorstore_data.as_retriever(search_kwargs={\"k\": k_initial}),\n",
    "            logger=logger,\n",
    "        )\n",
    "\n",
    "    def get_relevant_documents(self, query: str, workflow:int=1) -> List[Document]:\n",
    "        self.logger.info(f\"Worflow: {workflow}\")\n",
    "\n",
    "        if workflow == 2:\n",
    "            results = self.base_retriever_data.get_relevant_documents(query=query)\n",
    "            self.logger.info(f\"Retrieved {len(results)} documents\")\n",
    "            return results[:self.k_final]\n",
    "\n",
    "        else:\n",
    "            results =  self.base_retriever_all.get_relevant_documents(query=query)\n",
    "            self.logger.info(f\"Retrieved {len(results)} documents\")\n",
    "            if workflow == 1:\n",
    "                doc_ids = [doc.metadata[\"source\"] for doc in results]\n",
    "\n",
    "                # make it a set but keep the order\n",
    "                doc_ids = list(dict.fromkeys(doc_ids))[:self.k_final]\n",
    "\n",
    "                # log to the logger\n",
    "                self.logger.info(f\"Retrieved {len(doc_ids)} unique documents\")\n",
    "\n",
    "                # get upto 4 documents\n",
    "                full_retrieved_docs = [d for d in self.full_docs if d.metadata[\"source\"] in doc_ids]\n",
    "\n",
    "                return self.prepare_source(full_retrieved_docs)\n",
    "\n",
    "            full_retrieved_docs = results[:self.k_final]\n",
    "            return self.prepare_source(full_retrieved_docs)\n",
    "        \n",
    "    async def aget_relevant_documents(self, query: str) -> List[Document]:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def prepare_source(self, documents: List[Document]) -> List[Document]:\n",
    "        \n",
    "        for doc in documents:\n",
    "            source = doc.metadata[\"source\"]\n",
    "            if \"chunk\" in source:\n",
    "                source = source.split(\"chunk\")[0].strip()\n",
    "                doc.metadata[\"source\"] = source\n",
    "\n",
    "        return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-apfNELnY4pAbHrx6LItJCss8 on tokens per min. Limit: 1000000 / min. Current: 840504 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    }
   ],
   "source": [
    "with open(\"/home/marshath/play/chainlink/chainlink-assistant/data/documents_2023-08-14.pkl\", \"rb\") as f:\n",
    "    documents = pickle.load(f)\n",
    "\n",
    "with open(\"/home/marshath/play/chainlink/chainlink-assistant/data/datadocs_2023-08-16.pkl\", \"rb\") as f:\n",
    "    datadocs = pickle.load(f)\n",
    "\n",
    "# Split documents into chunks for 16k model\n",
    "full_doc_splitter = CustomeSplitter()\n",
    "chunked_full_documents = full_doc_splitter.split(documents)\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1200, chunk_overlap=50)\n",
    "split_docs = splitter.split_documents(documents)\n",
    "\n",
    "# Create vectorstore for all documents\n",
    "vectorstore_all = FAISS.from_documents(split_docs, embedding=OpenAIEmbeddings())\n",
    "\n",
    "# Split documents into chunks using datadocs\n",
    "split_docs_data = splitter.split_documents(datadocs)\n",
    "\n",
    "# Create vectorstore for datadocs\n",
    "vectorstore_data = FAISS.from_documents(split_docs_data, embedding=OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = CustomRetriever.from_documents(\n",
    "    chunked_full_documents, \n",
    "    vectorstore_all=vectorstore_all,\n",
    "    vectorstore_data=vectorstore_data,\n",
    "    k_initial=10, \n",
    "    k_final=4, \n",
    "    logger=logger\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "final_answer_system_template = \"\"\"\n",
    "As an AI assistant helping answer a user's question about Chainlink, your task is to provide the answer to the user's question based on the collection of documents provided. Each document is demarcated by the 'Source:' tag. \n",
    "\n",
    "In most cases, the answer to the user's question can be found in one of the documents.\n",
    "\n",
    "If the documents do not contain the required information to answer user's question, respond with 'I don't know'. In this case, you can provide a link to the Chainlink documentation.\n",
    "\n",
    "Each point in your answer should be formatted with corresponding reference(s) using markdown. Conclude your response with a footnote that enumerates all the references involved. Please make sure to use only the references provided in the documents and not to use any external references. \n",
    "\n",
    "The footnote should be formatted as follows: \n",
    "```\n",
    "References:\n",
    "[^1^]: <reference 1> \n",
    "[^2^]: <reference 2> \n",
    "[^3^]: <reference 3>\n",
    "```\n",
    "Please avoid duplicating references. For example, if the same reference is used twice in the answer, please only include it once in the footnote.\n",
    "\"\"\"\n",
    "\n",
    "final_answer_human_template = \"\"\"\n",
    "User's question: {question}\n",
    "\n",
    "Document: {document}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "FINAL_ANSWER_PROMPT = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessagePromptTemplate.from_template(final_answer_system_template),\n",
    "        HumanMessagePromptTemplate.from_template(final_answer_human_template),\n",
    "    ]\n",
    ")\n",
    "\n",
    "final_answer_2_system_template = \"\"\"\n",
    "As an AI assistant helping answer a user's question about Chainlink, your task is to provide the answer to the user's question based on the potential answers derived from previous LLM call(s). \n",
    "If the document doesn't contain the required information, respond with 'I don't know'.\n",
    "Each point in your answer should be formatted with corresponding reference(s) using markdown. Conclude your response with a footnote that enumerates all the references involved. \n",
    "\n",
    "The footnote should be formatted as follows: \n",
    "```\n",
    "References:\n",
    "[^1^]: <reference 1> \n",
    "[^2^]: <reference 2> \n",
    "[^3^]: <reference 3>\n",
    "```\n",
    "Please avoid duplicating references. For example, if the same reference is used twice in the answer, please only include it once in the footnote.\n",
    "\"\"\"\n",
    "\n",
    "final_answer_2_human_template = \"\"\"\n",
    "User's question: {question}\n",
    "\n",
    "Document: {document}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "FINAL_ANSWER_2_PROMPT = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessagePromptTemplate.from_template(final_answer_2_system_template),\n",
    "        HumanMessagePromptTemplate.from_template(final_answer_2_human_template),\n",
    "    ]\n",
    ")\n",
    "\n",
    "router_system_prompt = \"\"\"\n",
    "As an AI assistant helping ansswer a user's question about Chainlink, your first task is to route the question to the proper workflow. \n",
    "There are three workflows:\n",
    "    1. short-form which is suitable for simple questions. It is bad at answering questions requiring code output.\n",
    "    2. long-form which is suitable for complex questions. It is good at answering questions requiring code output.\n",
    "    3. is a specialized workflow for answering questions about Chainlink's price feeds. It is good at answering questions about Chainlink's price feeds.\n",
    "\n",
    "Sample questions for each workflow:\n",
    "\n",
    "Workflow 1: short-form\n",
    "- What is Chainlink?\n",
    "- What is a Chainlink node?\n",
    "- What is a Chainlink oracle?\n",
    "\n",
    "Workflow 2: long-form\n",
    "- give me a sample solidity contract to use Chainlink price feeds?\n",
    "- give me a sample solidity contract to use Chainlink VRF?\n",
    "- give me a sample solidity contract to use NFT Floor Price Feeds?\n",
    "- Give code examples to demonstrate how to deploy a consumer contract on-chain that reads a data feed and stores the value?\n",
    "\n",
    "Workflow 3: specialized\n",
    "- check if a feed is verified, ex: Is eth/usd a verified feed?\n",
    "- is eth/usd feed backed by staking?\n",
    "- under what asset class does eth/usd fall?\n",
    "- what is the tier of the eth/usd feed on binance?\n",
    "- what is the deviation threshold of eth/usd on binance?\n",
    "- how many oracles carry eth/usd on binance?\n",
    "\n",
    "Your output should be a number between 0 and 2. 0 means the question should be routed to the short-form workflow. 1 means the question should be routed to the long-form workflow. 2 means the question should be routed to the specialized workflow.\n",
    "\"\"\"\n",
    "\n",
    "router_human_prompt = \"\"\"\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "ROUTER_PROMPT = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessagePromptTemplate.from_template(router_system_prompt),\n",
    "        HumanMessagePromptTemplate.from_template(router_human_prompt),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_streaming_chain(chain, workflow):\n",
    "    \"\"\"Return a new streaming chain.\"\"\"\n",
    "\n",
    "    if workflow == 1:\n",
    "        llm_stream = ChatOpenAI(\n",
    "            temperature=0.0,\n",
    "            model=\"gpt-3.5-turbo-16k\",\n",
    "            streaming=True,\n",
    "            callbacks=[StreamingStdOutCallbackHandler()],\n",
    "        )\n",
    "        logger.info(\"Using long-form workflow\")\n",
    "        chain.llm = llm_stream\n",
    "    else:\n",
    "        llm_stream = ChatOpenAI(\n",
    "            temperature=0.0,\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            streaming=True,\n",
    "            # max_tokens=256,\n",
    "            callbacks=[StreamingStdOutCallbackHandler()],\n",
    "        )\n",
    "        chain.llm = llm_stream\n",
    "        logger.info(\"Using short-form workflow\")\n",
    "\n",
    "    return chain\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.)\n",
    "base_chain = LLMChain(llm=llm, prompt=FINAL_ANSWER_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = \"gpt-3.5-turbo\"\n",
    "try:\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "except KeyError:\n",
    "    logger.info(f\"Encoding for model {model} not found. Using default encoding.\")\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "\n",
    "def calculate_tokens(document, encoding):\n",
    "    \"\"\"Calculate the number of tokens in a list of documents.\"\"\"\n",
    "    return len(encoding.encode(document))\n",
    "\n",
    "\n",
    "def concatenate_documents(documents, max_tokens):\n",
    "    \"\"\"Combine documents up to a certain token limit.\"\"\"\n",
    "    combined_docs = \"\"\n",
    "    token_count = 0\n",
    "    used_docs = []\n",
    "\n",
    "    for doc in documents:\n",
    "        doc_tokens = calculate_tokens(doc.page_content, encoding)\n",
    "        if (token_count + doc_tokens) <= max_tokens:\n",
    "            combined_docs += f\"\\n\\n{doc.page_content}\\nSource: {doc.metadata['source']}\"\n",
    "            token_count += doc_tokens\n",
    "            used_docs.append(doc)\n",
    "\n",
    "    return combined_docs, used_docs\n",
    "\n",
    "\n",
    "def call_llm_final_answer(question, document, chain, stream=False):\n",
    "    \"\"\"Call LLM with a question and a single document.\"\"\"\n",
    "    chain.prompt = FINAL_ANSWER_PROMPT\n",
    "    if stream:\n",
    "        return chain.apredict(question=question, document=document)\n",
    "    else:\n",
    "        return chain.predict(question=question, document=document)\n",
    "\n",
    "\n",
    "def call_llm_final_2_answer(question, document, chain):\n",
    "    \"\"\"Call LLM with a question and a single document.\"\"\"\n",
    "    chain.prompt = FINAL_ANSWER_2_PROMPT\n",
    "    return chain.apredict(question=question, document=document)\n",
    "\n",
    "\n",
    "def process_documents(question, chain, max_tokens=14_000):\n",
    "    \"\"\"Process a list of documents with LLM calls.\"\"\"\n",
    "    \n",
    "    # Use router to decide which workflow to use\n",
    "    chain.prompt = ROUTER_PROMPT\n",
    "    try:\n",
    "        workflow = int(chain.predict(question=question))\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in router: {e}\")\n",
    "        workflow = 0\n",
    "\n",
    "    logger.info(f\"Using workflow {workflow}\")\n",
    "    print(f\"Using workflow {workflow}\")\n",
    "\n",
    "    documents = retriever.get_relevant_documents(question, workflow=workflow)\n",
    "    batches = []\n",
    "    num_llm_calls = 0\n",
    "    while documents:\n",
    "        batch, used_docs = concatenate_documents(documents, max_tokens)\n",
    "        batches.append(batch)\n",
    "        # logger.info(f\"Calling LLM with {batch}\")\n",
    "        documents = [doc for doc in documents if doc not in used_docs]\n",
    "        num_llm_calls += 1\n",
    "        logger.info(\n",
    "            f\"LLM call {num_llm_calls} complete. {len(documents)} documents remaining.\"\n",
    "        )\n",
    "\n",
    "    return batches, num_llm_calls, workflow\n",
    "\n",
    "\n",
    "async def get_answer(question,max_tokens=14_000):\n",
    "    \"\"\"Get an answer to a question.\"\"\"\n",
    "\n",
    "    # Main code that calls process_documents\n",
    "    batches, num_llm_calls, workflow = process_documents(\n",
    "        question=question, \n",
    "        max_tokens=max_tokens,\n",
    "        chain=base_chain\n",
    "    )\n",
    "\n",
    "    # Get the streaming chain\n",
    "    chain_stream = get_streaming_chain(\n",
    "        chain=base_chain,\n",
    "        workflow=workflow\n",
    "    )\n",
    "\n",
    "    if num_llm_calls == 1:\n",
    "        result = await call_llm_final_answer(\n",
    "            question=question, \n",
    "            document=batches[0], \n",
    "            chain=chain_stream, \n",
    "            stream=True\n",
    "        )\n",
    "        return result\n",
    "\n",
    "    else:\n",
    "        # Handle the list of batches\n",
    "        results = []\n",
    "        for batch in batches:\n",
    "            result = call_llm_final_answer(\n",
    "                question=question, \n",
    "                document=batch, \n",
    "                chain=base_chain\n",
    "            )\n",
    "            results.append(result)\n",
    "\n",
    "        combined_result = \" \".join(results)\n",
    "\n",
    "        logger.info(f\"Final LLM call with {len(results)} results.\")\n",
    "        combined_result = await call_llm_final_2_answer(\n",
    "            question=question, \n",
    "            document=combined_result, \n",
    "            chain=chain_stream\n",
    "        )\n",
    "\n",
    "        return combined_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1Using workflow 1\n",
      "To retrieve feed data from a price feed using web3.js, you can follow the steps below:\n",
      "\n",
      "1. Install the necessary tools: You will need to install the Solana CLI and Node.js 14 or higher. Make sure you have these tools installed on your system[^1^].\n",
      "\n",
      "2. Import the required libraries: In your JavaScript or TypeScript code, import the necessary libraries for interacting with Chainlink and Solana. You will need to import `@project-serum/anchor` and `@chainlink/solana-sdk`[^1^].\n",
      "\n",
      "3. Set up the provider: Create an instance of the AnchorProvider and set it as the provider for the anchor library[^1^].\n",
      "\n",
      "4. Load the data feed account: Use the `OCR2Feed.load` function to load the data feed account. Pass in the program ID and provider as arguments[^1^].\n",
      "\n",
      "5. Listen for events: Use the `onRound` function to listen for events against the price feed. Pass in the feed address and a callback function that will be executed when an event is emitted[^1^].\n",
      "\n",
      "6. Block execution and wait for events: Use the `await` keyword to block execution and wait for events to be emitted with price data[^1^].\n",
      "\n",
      "Here is an example code snippet in JavaScript:\n",
      "\n",
      "```javascript\n",
      "const anchor = require(\"@project-serum/anchor\");\n",
      "const chainlink = require(\"@chainlink/solana-sdk\");\n",
      "const provider = anchor.AnchorProvider.env();\n",
      "\n",
      "async function main() {\n",
      "  anchor.setProvider(provider);\n",
      "\n",
      "  const CHAINLINK_FEED_ADDRESS = \"99B2bTijsU6f1GCT73HmdR7HCFFjGMBcPZY6jZ96ynrR\";\n",
      "  const CHAINLINK_PROGRAM_ID = new anchor.web3.PublicKey(\"cjg3oHmg9uuPsP8D6g29NWvhySJkdYdAo9D25PRbKXJ\");\n",
      "  const feedAddress = new anchor.web3.PublicKey(CHAINLINK_FEED_ADDRESS);\n",
      "\n",
      "  let dataFeed = await chainlink.OCR2Feed.load(CHAINLINK_PROGRAM_ID, provider);\n",
      "  let listener = null;\n",
      "\n",
      "  listener = dataFeed.onRound(feedAddress, (event) => {\n",
      "    console.log(event.answer.toNumber());\n",
      "  });\n",
      "\n",
      "  await new Promise(function () {});\n",
      "}\n",
      "\n",
      "main().then(\n",
      "  () => process.exit(),\n",
      "  (err) => {\n",
      "    console.error(err);\n",
      "    process.exit(-1);\n",
      "  }\n",
      ");\n",
      "```\n",
      "\n",
      "Please note that this is just an example code snippet and you may need to modify it based on your specific requirements and environment.\n",
      "\n",
      "References:\n",
      "[^1^]: [Using Data Feeds Off-Chain (Solana)](https://docs.chain.link/data-feeds/solana/using-data-feeds-off-chain/)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'To retrieve feed data from a price feed using web3.js, you can follow the steps below:\\n\\n1. Install the necessary tools: You will need to install the Solana CLI and Node.js 14 or higher. Make sure you have these tools installed on your system[^1^].\\n\\n2. Import the required libraries: In your JavaScript or TypeScript code, import the necessary libraries for interacting with Chainlink and Solana. You will need to import `@project-serum/anchor` and `@chainlink/solana-sdk`[^1^].\\n\\n3. Set up the provider: Create an instance of the AnchorProvider and set it as the provider for the anchor library[^1^].\\n\\n4. Load the data feed account: Use the `OCR2Feed.load` function to load the data feed account. Pass in the program ID and provider as arguments[^1^].\\n\\n5. Listen for events: Use the `onRound` function to listen for events against the price feed. Pass in the feed address and a callback function that will be executed when an event is emitted[^1^].\\n\\n6. Block execution and wait for events: Use the `await` keyword to block execution and wait for events to be emitted with price data[^1^].\\n\\nHere is an example code snippet in JavaScript:\\n\\n```javascript\\nconst anchor = require(\"@project-serum/anchor\");\\nconst chainlink = require(\"@chainlink/solana-sdk\");\\nconst provider = anchor.AnchorProvider.env();\\n\\nasync function main() {\\n  anchor.setProvider(provider);\\n\\n  const CHAINLINK_FEED_ADDRESS = \"99B2bTijsU6f1GCT73HmdR7HCFFjGMBcPZY6jZ96ynrR\";\\n  const CHAINLINK_PROGRAM_ID = new anchor.web3.PublicKey(\"cjg3oHmg9uuPsP8D6g29NWvhySJkdYdAo9D25PRbKXJ\");\\n  const feedAddress = new anchor.web3.PublicKey(CHAINLINK_FEED_ADDRESS);\\n\\n  let dataFeed = await chainlink.OCR2Feed.load(CHAINLINK_PROGRAM_ID, provider);\\n  let listener = null;\\n\\n  listener = dataFeed.onRound(feedAddress, (event) => {\\n    console.log(event.answer.toNumber());\\n  });\\n\\n  await new Promise(function () {});\\n}\\n\\nmain().then(\\n  () => process.exit(),\\n  (err) => {\\n    console.error(err);\\n    process.exit(-1);\\n  }\\n);\\n```\\n\\nPlease note that this is just an example code snippet and you may need to modify it based on your specific requirements and environment.\\n\\nReferences:\\n[^1^]: [Using Data Feeds Off-Chain (Solana)](https://docs.chain.link/data-feeds/solana/using-data-feeds-off-chain/)'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await get_answer(\"Write code to show how to use web3.js to retrieve feed data from a price feed?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chainlink",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
